from llmanlp.models import LlamaForSequenceClassification
from safetensors.torch import load, save
import torch

# Paths to your SafetyTensors model parts
model_parts = [
    './path_to_safety_tensors/model-00001-of-00004.safetensors',
    './path_to_safety_tensors/model-00002-of-00004.safetensors',
    './path_to_safety_tensors/model-00003-of-00004.safetensors',
    './path_to_safety_tensors/model-00004-of-00004.safetensors'
]

# Load and concatenate the model parts
model_weights = None
for part in model_parts:
    part_data = load(part)['obj']  # Assuming the model data is stored under 'obj'
    if model_weights is None:
        model_weights = part_data
    else:
        model_weights = torch.cat((model_weights, part_data), 0)  # Adjust dimension if necessary

# Load the configuration
config_path = './path_to_safety_tensors/config.json'
with open(config_path, 'r') as file:
    config = json.load(file)

# Initialize the model with the loaded configuration and concatenated weights
model = LlamaForSequenceClassification(config=config)
model.load_state_dict(model_weights, strict=False)  # Use strict=False if the weights need adjustments

# Save the complete model to a local directory
save_directory = './my_local_directory/llama_for_sequence_classification'
model.save_pretrained(save_directory)

print(f"Complete model loaded and saved in {save_directory}")
